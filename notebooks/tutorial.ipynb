{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial notebook on working with the DeepEF model\n",
    "\n",
    "This tuturial will contain neccesary information on how to work and use the DeepEF model on a veriaty of cases:\n",
    "1. Energy prediction.\n",
    "2. PDB energy prediction\n",
    "3. $\\Delta G$ and $\\Delta \\Delta G$ prediction for mutation outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Free energy prediction $G$\n",
    "The DeepEF model enable users to predict rapidly the energy of a protein, since it is not a mesurable value it can be use to predict stability of a protien, mutation outcome and more.\n",
    "\n",
    "In this section Ill show how to use the proccesed sidechaine data to predict the energy of a protein.\n",
    "\n",
    "The DeepEF input is a normelized protein graph created from the structure and sequence.\n",
    "\n",
    "The protein graph containes:\n",
    "1. A summed distence matrix\n",
    "2. A one hot vector of the sequence\n",
    "3. ProT5 embedding of the sequence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')    # add parent directory to path   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shaharcohen/opt/anaconda3/envs/deepef/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Necessary imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from model.hydro_net import PEM\n",
    "from model.model_cfg import CFG\n",
    "from Utils.train_utils import *\n",
    "from Utils.pdb_parser import get_pdb_data\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 393517\n"
     ]
    }
   ],
   "source": [
    "# Import the model\n",
    "model = PEM(layers=CFG.num_layers,gaussian_coef=CFG.gaussian_coef).to(CFG.device)\n",
    "# Get total number of parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Number of parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload model weights\n",
    "CFG.model_path = '../data/Trained_models/'\n",
    "epoch = 25\n",
    "model_dict = torch.load(CFG.model_path+f\"{epoch}_final_model.pt\",map_location=CFG.device,weights_only=False)\n",
    "model.load_state_dict(model_dict['model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 10#1HF2_1_A\n",
      "crd_backbone: torch.Size([1, 210, 4, 3])\n",
      "mask: torch.Size([1, 210])\n",
      "seq_one_hot: torch.Size([1, 210, 20])\n",
      "seq: MVDFKMTKEGLVLLIKDYQNLEEVLNAISARITQMGGFFAKGDRISLMIENHNKHSQDIPRIVSHLRNLGLEVSQILVGSTVEGKENDLKVQSRTTVESTGKVIKRNIRSGQTVVHSGDVIVFGNVNKGAEILAGGSVVVFGKAQGNIRAGLNEGGQAVVAALDLQTSLIQIAGFITHSKGEENVPSIAHVKGNRIVIEPFDKVSFERSE\n",
      "proT5_emb: torch.Size([1, 210, 1024])\n"
     ]
    }
   ],
   "source": [
    "item_path = '../data/casp12_data_30/valid-10/10#1HF2_1_A'\n",
    "\n",
    "data = get_item_data(item_path)\n",
    "\n",
    "def print_shapes(data):\n",
    "    id, crd_backbone, mask, seq_one_hot, seq, proT5_emb = data\n",
    "    print(f\"id: {id}\")\n",
    "    print(f\"crd_backbone: {crd_backbone.shape}\")\n",
    "    print(f\"mask: {mask.shape}\")\n",
    "    print(f\"seq_one_hot: {seq_one_hot.shape}\")\n",
    "    print(f\"seq: {seq}\")\n",
    "    print(f\"proT5_emb: {proT5_emb.shape}\")\n",
    "    return\n",
    "print_shapes(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "The energy of 10#1HF2_1_A protein is: -40.55464172363281\n"
     ]
    }
   ],
   "source": [
    "# Get the prediction\n",
    "model.eval()\n",
    "# get the graph\n",
    "id, crd_backbone, mask, seq_one_hot, seq, proT5_emb = data\n",
    "protein_graph = get_graph(crd_backbone.squeeze(),seq_one_hot.squeeze(), proT5_emb.squeeze(),mask.squeeze())\n",
    "\n",
    "# get the prediction\n",
    "with torch.no_grad():\n",
    "    Gf = model(protein_graph.unsqueeze(0))\n",
    "    Gf = Gf.cpu().numpy()\n",
    "    Gf = Gf[0]\n",
    "    print(Gf.shape) \n",
    "    print(f\"The energy of {id} protein is: {Gf}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the $\\Delta G$ of the protein\n",
    "The $\\Delta G$ of the protein can be defined as follow: \n",
    "$$\\Delta G = G_{unfolded} - G_{folded}$$\n",
    "As it represent the change in energy between 2 conditions of a protein, folded and unfolded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "The energy of 10#1HF2_1_A protein unfolded structure is: -3.834486722946167\n",
      "The deltaG is: 36.72015380859375\n"
     ]
    }
   ],
   "source": [
    "unfolde_graph = get_unfolded_graph(crd_backbone.squeeze(),seq_one_hot.squeeze(), proT5_emb.squeeze(),mask.squeeze())\n",
    "with torch.no_grad():\n",
    "    Gu = model(unfolde_graph.unsqueeze(0))\n",
    "    Gu = Gu.cpu().numpy()\n",
    "    Gu = Gu[0]\n",
    "    print(Gu.shape)\n",
    "    print(f\"The energy of {id} protein unfolded structure is: {Gu}\")\n",
    "    \n",
    "# Calculate the deltaG\n",
    "deltaG = Gu - Gf\n",
    "print(f\"The deltaG is: {deltaG}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDB energy prediction\n",
    "To use the DeepEF model on an existing pdb you will need to use out functions for data extraction and graph creation.\n",
    "\n",
    "The steps for predicting energy for a given PDB is:\n",
    "1. Specify pdb path\n",
    "2. extrance sequence and coordinate\n",
    "3. Obtain protein graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shaharcohen/Documents/DeepEF-protein-EF/notebooks/../Utils/pdb_parser.py:73: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  coords = torch.tensor(coords)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: Rostlab/prot_t5_xl_half_uniref50-enc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "pdb_path  = \"../data/pdb_files/1A0F.pdb\"\n",
    "pdb_data = get_pdb_data(pdb_path,chain_id='A')\n",
    "pdb_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['coords', 'sequence', 'mask_tensor', 'proT5_emb'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdb_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "The energy of 10#1HF2_1_A protein is: -42.57391357421875\n"
     ]
    }
   ],
   "source": [
    "# get the graph\n",
    "crd_backbone, mask, seq_one_hot, seq, proT5_emb = pdb_data[\"coords\"], pdb_data[\"mask_tensor\"],\\\n",
    "    get_one_hot(pdb_data[\"sequence\"]), pdb_data[\"sequence\"], pdb_data[\"proT5_emb\"]\n",
    "protein_graph = get_graph(crd_backbone.squeeze(),seq_one_hot.squeeze(), proT5_emb.squeeze(),mask.squeeze())\n",
    "\n",
    "# get the prediction\n",
    "with torch.no_grad():\n",
    "    Gf = model(protein_graph.unsqueeze(0))\n",
    "    Gf = Gf.cpu().numpy()\n",
    "    Gf = Gf[0]\n",
    "    print(Gf.shape) \n",
    "    print(f\"The energy of {id} protein is: {Gf}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepef",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
